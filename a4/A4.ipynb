{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8e34b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c127e87",
   "metadata": {},
   "source": [
    "# Part 1: Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2401f343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                 5.1               3.5                1.4               0.2\n",
       "1                 4.9               3.0                1.4               0.2\n",
       "2                 4.7               3.2                1.3               0.2\n",
       "3                 4.6               3.1                1.5               0.2\n",
       "4                 5.0               3.6                1.4               0.2\n",
       "5                 5.4               3.9                1.7               0.4\n",
       "6                 4.6               3.4                1.4               0.3\n",
       "7                 5.0               3.4                1.5               0.2\n",
       "8                 4.4               2.9                1.4               0.2\n",
       "9                 4.9               3.1                1.5               0.1\n",
       "10                5.4               3.7                1.5               0.2\n",
       "11                4.8               3.4                1.6               0.2\n",
       "12                4.8               3.0                1.4               0.1\n",
       "13                4.3               3.0                1.1               0.1\n",
       "14                5.8               4.0                1.2               0.2"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (load remotely, not locally)\n",
    "# Output the first 15 rows of the data\n",
    "d = datasets.load_iris()\n",
    "data = pd.DataFrame(d.data, columns=d.feature_names)\n",
    "data.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f37df74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the table information (number of datapoints, etc.)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38524eb8",
   "metadata": {},
   "source": [
    "### About the dataset\n",
    "Explain what the data is in your own words. What are your features and labels? What is the mapping of your labels to the actual classes? \n",
    "* The Iris data set is composed of 150 data samples across 3 different iris variations. Each iris variant have 50 samples that records many features of each individual flower. The labels include Setosa, Veriscolor, and Virginica. As for the features: We have the measurements of the sepal length, sepal width, petal length and petal width.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc623f27",
   "metadata": {},
   "source": [
    "# Part 2: Split the dataset into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8e0ae875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 4) (15, 4) (135,) (15,)\n"
     ]
    }
   ],
   "source": [
    "# Take the dataset and split it into our features (X) and label (y)\n",
    "X = d.data\n",
    "y = d.target\n",
    "# Use sklearn to split the features and labels into a training/test set. (90% train, 10% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, test_size=0.1)\n",
    "# 135 went into train set, 15 went into test\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ba752",
   "metadata": {},
   "source": [
    "# Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "3955ad91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a LogisticRegression model on the training set\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dcf9f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for Logistic regression model, what does the score measure?\n",
    "score = logisticRegr.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e311d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41299308  0.93238632 -2.43006944 -1.04809455]\n",
      " [ 0.56795794 -0.31447395 -0.23280627 -0.88790594]\n",
      " [-0.15496487 -0.61791237  2.66287572  1.9360005 ]] [  9.60720475   1.94978397 -11.55698871]\n"
     ]
    }
   ],
   "source": [
    "# iv. Extract the coefficents and intercepts for the boundary line(s)\n",
    "print(logisticRegr.coef_, logisticRegr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd93a7b",
   "metadata": {},
   "source": [
    "### Score = ```1.0```\n",
    "* After applying our Logistic Regression Model onto the training set, We tried to predict the results for a sample datapoint. The sample score obtained was ```1.0```. This score is exactly 1.0 which means that this model can be said most accurate based on the data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e61f94",
   "metadata": {},
   "source": [
    "# Part 4: Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "819622e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Support Vector Classifier on the training set\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e617f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the SVM, what does the score measure?\n",
    "svm_score = model.score(X_test, y_test)\n",
    "print(svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c305e",
   "metadata": {},
   "source": [
    "### Score = ```0.93```\n",
    "* After applying our Logistic Regression Model onto the training set, We tried to predict the results for a sample datapoint. The sample score obtained was ```0.93```. This score is fairly close to 1.0 which means that this model can be said to be fairly accurate based on the data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcab523",
   "metadata": {},
   "source": [
    "# Part 5: Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "33420f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to train a Neural Network (MLP Classifier) on the training set\n",
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(4,2), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0092d227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for the Neural Network, what does the score measure?\n",
    "mlp_score = mlp.score(X_test, y_test)\n",
    "# iv: Experiment with different options for the neural network, report on your best configuration (the highest score I was able to achieve was 0.8666)\n",
    "print(mlp_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025f349",
   "metadata": {},
   "source": [
    "# Part 6: K-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7674d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i. Use sklearn to 'train' a k-Neighbors Classifier\n",
    "# Note: KNN is a nonparametric model and technically doesn't require training\n",
    "# fit will essentially load the data into the model see link below for more information\n",
    "# https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier\n",
    "K = 3\n",
    "knn = KNeighborsClassifier(K)\n",
    "knn.fit(X_train, y_train)\n",
    "# ii. For a sample datapoint, predict the probabilities for each possible class\n",
    "knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "10ecf93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# iii. Report on the score for kNN, what does the score measure?\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3a9fed",
   "metadata": {},
   "source": [
    "### Score = ```1.0```\n",
    "* After applying our Logistic Regression Model onto the training set, We tried to predict the results for a sample datapoint. The sample score obtained was ```1.0```. This score is exactly 1.0 which means that this model can be said most accurate based on the data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2cf5a",
   "metadata": {},
   "source": [
    "# Part 7: Conclusions and takeaways\n",
    "In your own words describe the results of the notebook. Which model(s) performed the best on the dataset? Why do you think that is? Did anything surprise you about the exercise?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33987b",
   "metadata": {},
   "source": [
    "### Findings\n",
    "#### This experiment lead to utilizing multiple different machine learning tools on the famous iris-dataset. There were certainly some models that had overall, performed better on this dataset than others. \n",
    "* In this case, the models with good and consistent performance were: Logistic Regression, SVM, and K-Nearest Neighbors.\n",
    "These 3 models had the highest scores across the board for all the models used. The reasons could vary from being on how effective some models are on small datasets vs large datasets. For the iris dataset, we consider it to be relatively small with ~150 samples. It may be the case that these models perform better on the smaller sets compared to other models. \n",
    "* Another possible case could be that the methods that a model follows isn't the most effective on this dataset. From our results, we note that Neural Networks performance is relatively inconsistent and somewhat low. The score for neural network is consistently lower due to the number of possible configurations we must optimize. On some occassions, I've gotton scores of ```0.266``` and ```1.0``` on others. \n",
    "\n",
    "* What had surprised me overall about this exercise, is how powerful these tools are and that it is necessary to learn where to best apply what model. All of these models worked incredibly fast and to be able to determine/predict these outcomes based on using recorded data is certainly impressive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
